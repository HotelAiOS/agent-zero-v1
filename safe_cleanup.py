#!/usr/bin/env python3
"""
GitHub-based Safe Cleanup Script for Agent Zero V1
Przenosi potencjalne Å›mieci do folderu review zamiast usuwania
"""

import os
import shutil
import subprocess
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple

class SafeCleanupManager:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.cleanup_dir = self.project_root / "_cleanup_review"
        self.log_file = self.cleanup_dir / "cleanup_log.txt"
        
    def analyze_and_move_junk(self):
        """GÅ‚Ã³wna funkcja - analiza i przeniesienie Å›mieci"""
        
        # StwÃ³rz folder review
        self.cleanup_dir.mkdir(exist_ok=True)
        
        # Identyfikuj pliki do przeniesienia
        files_to_move = self.identify_junk_files()
        
        # Generuj raport
        self.generate_cleanup_report(files_to_move)
        
        # PrzenieÅ› pliki z potwierdzeniem
        self.move_files_with_confirmation(files_to_move)
        
        return files_to_move
    
    def identify_junk_files(self) -> Dict[str, List[Path]]:
        """Identyfikuje potencjalne Å›mieci na podstawie wzorcÃ³w"""
        
        junk_categories = {
            'backup_files': [],
            'duplicate_versions': [],
            'old_configs': [],
            'temp_files': [],
            'database_files': []
        }
        
        # 1. Backup files - 100% pewnoÅ›ci
        for pattern in ['*.bak', '*.backup', '*_backup*', '*.yml.bak_*']:
            junk_categories['backup_files'].extend(self.project_root.glob(pattern))
        
        # 2. Database files w repo - nie powinny byÄ‡ w Git
        db_files = list(self.project_root.glob('*.db')) + list(self.project_root.glob('*.sqlite*'))
        junk_categories['database_files'] = db_files
        
        # 3. Duplicate versions - analizuj podobne nazwy
        junk_categories['duplicate_versions'] = self.find_version_duplicates()
        
        # 4. Old configs - wielokrotne wersje tego samego
        junk_categories['old_configs'] = self.find_config_duplicates()
        
        # 5. Temp i test files
        temp_patterns = ['*_temp.py', '*_test_*.py', '*_backup.py', '*_old.py', '*_fixed.py']
        for pattern in temp_patterns:
            junk_categories['temp_files'].extend(self.project_root.glob(pattern))
        
        return junk_categories
    
    def find_version_duplicates(self) -> List[Path]:
        """Znajduje duplikaty bazujÄ…c na nazwach i timestamp"""
        
        duplicates = []
        
        # Grupuj pliki po base name (bez -fixed, -v2, etc)
        file_groups = {}
        
        for py_file in self.project_root.glob('*.py'):
            # WyciÄ…gnij base name
            base_name = self.extract_base_name(py_file.stem)
            
            if base_name in file_groups:
                file_groups[base_name].append(py_file)
            else:
                file_groups[base_name] = [py_file]
        
        # Dla kaÅ¼dej grupy, zachowaj najnowszy/najlepszy
        for base_name, files in file_groups.items():
            if len(files) > 1:
                # Sortuj po dacie modyfikacji (najnowszy pierwszy)
                files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
                
                # Pierwszy to najnowszy - zachowaj
                # Reszta to potencjalne duplikaty
                potential_dupes = files[1:]
                
                # Dodatkowa weryfikacja - nie ruszaj jeÅ›li rÃ³Å¼nice w zawartoÅ›ci
                keeper = files[0]
                for dupe in potential_dupes:
                    if self.are_significantly_different(keeper, dupe):
                        continue  # Zachowaj jeÅ›li znaczÄ…ce rÃ³Å¼nice
                    duplicates.append(dupe)
        
        return duplicates
    
    def extract_base_name(self, filename: str) -> str:
        """WyciÄ…ga bazowÄ… nazwÄ™ bez suffixÃ³w typu -fixed, -v2"""
        
        # UsuÅ„ typowe suffixes
        suffixes_to_remove = [
            '-fixed', '-complete', '-standalone', '-production', 
            '-enhanced', '-v2', '-v3', '-final', '-new', '-old',
            '_fixed', '_complete', '_standalone', '_production'
        ]
        
        base = filename.lower()
        for suffix in suffixes_to_remove:
            base = base.replace(suffix, '')
        
        return base
    
    def find_config_duplicates(self) -> List[Path]:
        """Znajduje duplikaty konfiguracji"""
        
        config_files = []
        
        # Docker compose duplikates
        docker_files = list(self.project_root.glob('docker-compose*.yml'))
        if len(docker_files) > 1:
            # Zachowaj docker-compose.yml lub najnowszy
            docker_files.sort(key=lambda f: (
                0 if f.name == 'docker-compose.yml' else 1,  # Priorytet dla standardowej nazwy
                -f.stat().st_mtime  # Potem najnowszy
            ))
            config_files.extend(docker_files[1:])  # Reszta to duplikaty
        
        # Config.py duplikates  
        config_py_files = list(self.project_root.glob('config*.py'))
        if len(config_py_files) > 1:
            config_py_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
            config_files.extend(config_py_files[1:])
        
        return config_files
    
    def are_significantly_different(self, file1: Path, file2: Path) -> bool:
        """Sprawdza czy pliki rÃ³Å¼niÄ… siÄ™ znaczÄ…co"""
        
        try:
            with open(file1, 'r', encoding='utf-8', errors='ignore') as f1:
                content1 = f1.read()
            with open(file2, 'r', encoding='utf-8', errors='ignore') as f2:
                content2 = f2.read()
            
            # UsuÅ„ whitespace i komentarze dla porÃ³wnania
            clean1 = self.clean_content_for_comparison(content1)
            clean2 = self.clean_content_for_comparison(content2)
            
            # JeÅ›li rÃ³Å¼nica > 20% to znaczÄ…ce rÃ³Å¼nice
            if len(clean1) == 0 and len(clean2) == 0:
                return False
            
            similarity = self.calculate_similarity(clean1, clean2)
            return similarity < 0.8  # Mniej niÅ¼ 80% podobieÅ„stwa = znaczÄ…ce rÃ³Å¼nice
            
        except Exception:
            return True  # W razie bÅ‚Ä™du, zachowaj bezpiecznie
    
    def clean_content_for_comparison(self, content: str) -> str:
        """CzyÅ›ci zawartoÅ›Ä‡ do porÃ³wnania"""
        import re
        
        # UsuÅ„ komentarze
        content = re.sub(r'#.*', '', content)
        # UsuÅ„ puste linie
        content = re.sub(r'\n\s*\n', '\n', content)
        # Normalizuj whitespace
        content = re.sub(r'\s+', ' ', content)
        
        return content.strip()
    
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """Oblicza podobieÅ„stwo miÄ™dzy tekstami"""
        
        if len(text1) == 0 and len(text2) == 0:
            return 1.0
        if len(text1) == 0 or len(text2) == 0:
            return 0.0
        
        # Prosta miara podobieÅ„stwa bazowana na common substring
        common_length = 0
        min_length = min(len(text1), len(text2))
        
        for i in range(min_length):
            if text1[i] == text2[i]:
                common_length += 1
            else:
                break
        
        return common_length / max(len(text1), len(text2))
    
    def generate_cleanup_report(self, files_to_move: Dict[str, List[Path]]):
        """Generuje szczegÃ³Å‚owy raport cleanup"""
        
        report = []
        report.append(f"# Agent Zero V1 - Cleanup Report")
        report.append(f"Generated: {datetime.now()}")
        report.append(f"=" * 50)
        
        total_files = sum(len(files) for files in files_to_move.values())
        report.append(f"\nTotal files to review: {total_files}")
        
        for category, files in files_to_move.items():
            if files:
                report.append(f"\n## {category.upper()} ({len(files)} files):")
                for file_path in files:
                    size_kb = file_path.stat().st_size / 1024
                    modified = datetime.fromtimestamp(file_path.stat().st_mtime)
                    report.append(f"  - {file_path.name} ({size_kb:.1f}KB, {modified.strftime('%Y-%m-%d %H:%M')})")
        
        # Zapisz raport
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        # WyÅ›wietl na konsoli
        print('\n'.join(report))
    
    def move_files_with_confirmation(self, files_to_move: Dict[str, List[Path]]):
        """Przenosi pliki z opcjÄ… potwierdzenia"""
        
        total_files = sum(len(files) for files in files_to_move.values())
        
        if total_files == 0:
            print("âœ… Nie znaleziono plikÃ³w do przeniesienia.")
            return
        
        print(f"\nğŸ” Znaleziono {total_files} plikÃ³w do przeglÄ…du.")
        print(f"ğŸ“ ZostanÄ… przeniesione do: {self.cleanup_dir}")
        
        choice = input("\nWybierz akcjÄ™:\n1. PrzenieÅ› wszystkie\n2. PrzeglÄ…d po kategorii\n3. Anuluj\nWybÃ³r (1/2/3): ")
        
        if choice == '1':
            self.move_all_files(files_to_move)
        elif choice == '2':
            self.move_with_category_review(files_to_move)
        else:
            print("âŒ Anulowano.")
    
    def move_all_files(self, files_to_move: Dict[str, List[Path]]):
        """Przenosi wszystkie pliki"""
        
        moved_count = 0
        
        for category, files in files_to_move.items():
            category_dir = self.cleanup_dir / category
            category_dir.mkdir(exist_ok=True)
            
            for file_path in files:
                try:
                    destination = category_dir / file_path.name
                    shutil.move(str(file_path), str(destination))
                    moved_count += 1
                    print(f"ğŸ“¦ Przeniesiono: {file_path.name}")
                except Exception as e:
                    print(f"âŒ BÅ‚Ä…d przenoszenia {file_path.name}: {e}")
        
        print(f"\nâœ… Przeniesiono {moved_count} plikÃ³w do {self.cleanup_dir}")
        print(f"ğŸ“ SzczegÃ³Å‚y w: {self.log_file}")
    
    def move_with_category_review(self, files_to_move: Dict[str, List[Path]]):
        """Przenosi z przeglÄ…dem po kategoriach"""
        
        for category, files in files_to_move.items():
            if not files:
                continue
                
            print(f"\nğŸ“‚ Kategoria: {category} ({len(files)} plikÃ³w)")
            for file_path in files:
                print(f"  - {file_path.name}")
            
            choice = input(f"PrzenieÅ›Ä‡ pliki z kategorii '{category}'? (y/n/s=skip): ")
            
            if choice.lower() == 'y':
                category_dir = self.cleanup_dir / category
                category_dir.mkdir(exist_ok=True)
                
                for file_path in files:
                    try:
                        destination = category_dir / file_path.name
                        shutil.move(str(file_path), str(destination))
                        print(f"ğŸ“¦ Przeniesiono: {file_path.name}")
                    except Exception as e:
                        print(f"âŒ BÅ‚Ä…d: {e}")
            elif choice.lower() == 's':
                continue
            else:
                print("â­ï¸ PominiÄ™to kategoriÄ™")


# Funkcja uruchomieniowa
def main():
    print("ğŸ§¹ Agent Zero V1 - Safe Cleanup Tool")
    print("=" * 40)
    
    cleaner = SafeCleanupManager()
    files_found = cleaner.analyze_and_move_junk()
    
    print("\nğŸ¯ Cleanup zakoÅ„czony!")
    print(f"ğŸ“ Pliki przeniesione do: {cleaner.cleanup_dir}")
    print("ğŸ’¡ MoÅ¼esz je przejrzeÄ‡ i usunÄ…Ä‡ rÄ™cznie lub przywrÃ³ciÄ‡ jeÅ›li potrzebne.")

if __name__ == "__main__":
    main()
