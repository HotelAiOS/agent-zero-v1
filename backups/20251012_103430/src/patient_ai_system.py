#!/usr/bin/env python3
"""
Agent Zero V2.0 Phase 4 - Cierpliwy System AI z KontrolÄ… Å»ycia
Daje specjalistom czas (do 1h), ale z kontrolÄ… czy pracujÄ… (5min bez znaku Å¼ycia = przeÅ‚Ä…czenie)
"""

import requests
import time
import threading
from datetime import datetime
from queue import Queue, Empty

class ModelTimeout(Exception):
    pass

class ModelUnresponsive(Exception):
    pass

def heartbeat_monitor(req_func, result_queue, heartbeat_interval=300, max_total_time=3600):
    """
    Monitoruje model przez max 1h z heartbeat co 5min
    JeÅ›li 5min bez odpowiedzi = model uznany za martwy
    """
    start_time = time.time()
    last_heartbeat = start_time
    
    while True:
        try:
            # PrÃ³ba wywoÅ‚ania modelu z krÃ³tkim timeoutem
            response = req_func(timeout=20)
            
            if response.status_code == 200:
                # Model odpowiedziaÅ‚ - sukces!
                result_queue.put(("success", response))
                return
            else:
                # Model odpowiedziaÅ‚ bÅ‚Ä™dem, ale Å¼yje
                current_time = time.time()
                last_heartbeat = current_time
                
                # SprawdÅº czy nie przekroczono max czasu
                if current_time - start_time > max_total_time:
                    result_queue.put(("timeout", f"Model nie ukoÅ„czyÅ‚ zadania w {max_total_time/60:.0f} minut"))
                    return
                    
                print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ’“ Model Å¼yje, ale wciÄ…Å¼ pracuje...")
                time.sleep(30)  # Sprawdzaj czÄ™Å›ciej jeÅ›li model daje odpowiedzi bÅ‚Ä™dne
                
        except requests.Timeout:
            current_time = time.time()
            
            # SprawdÅº czy to pierwszy timeout czy kolejny
            time_since_last_heartbeat = current_time - last_heartbeat
            
            if time_since_last_heartbeat > heartbeat_interval:
                # Za dÅ‚ugo bez znaku Å¼ycia
                result_queue.put(("unresponsive", f"Brak znaku Å¼ycia przez {time_since_last_heartbeat/60:.1f} minut"))
                return
            elif current_time - start_time > max_total_time:
                # Przekroczony maksymalny czas
                result_queue.put(("timeout", f"Limit czasu {max_total_time/60:.0f} minut przekroczony"))
                return
            else:
                # Model moÅ¼e pracowaÄ‡ - daj mu wiÄ™cej czasu
                print(f"[{datetime.now().strftime('%H:%M:%S')}] â³ Specjalista myÅ›li... ({(current_time-start_time)/60:.1f}min)")
                time.sleep(30)  # Sprawdzaj co 30s podczas timeout
                
        except requests.RequestException as e:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ Problem z poÅ‚Ä…czeniem: {e}")
            time.sleep(10)
            continue

class PatientAISystem:
    def __init__(self, ollama_host="localhost", ollama_port=11434):
        self.ollama_url = f"http://{ollama_host}:{ollama_port}"
        
        # Modele uporzÄ…dkowane wedÅ‚ug specjalizacji i reliability
        self.model_hierarchy = {
            "coding": [
                {
                    "name": "codellama:13b",
                    "type": "specialist", 
                    "description": "Specjalista od kodowania",
                    "max_wait_time": 3600,  # 1h dla specjalisty
                    "heartbeat_interval": 300,  # 5min bez znaku Å¼ycia = fail
                    "quality_score": 10
                },
                {
                    "name": "deepseek-coder:33b",
                    "type": "expert", 
                    "description": "Ekspert kodowania (duÅ¼y model)",
                    "max_wait_time": 3600,  # 1h dla eksperta
                    "heartbeat_interval": 300,
                    "quality_score": 10
                },
                {
                    "name": "llama3.1:8b",
                    "type": "generalist", 
                    "description": "Generalista z dobrym kodowaniem",
                    "max_wait_time": 300,  # 5min dla generalisty
                    "heartbeat_interval": 120,
                    "quality_score": 8
                },
                {
                    "name": "llama3.2:3b",
                    "type": "fallback", 
                    "description": "Szybki fallback",
                    "max_wait_time": 120,
                    "heartbeat_interval": 60,
                    "quality_score": 6
                }
            ],
            "reasoning": [
                {
                    "name": "qwen2.5:14b",
                    "type": "specialist", 
                    "description": "Specjalista od zaawansowanego myÅ›lenia",
                    "max_wait_time": 3600,
                    "heartbeat_interval": 300,
                    "quality_score": 10
                },
                {
                    "name": "mixtral:8x7b",
                    "type": "expert", 
                    "description": "Ekspert zÅ‚oÅ¼onego myÅ›lenia",
                    "max_wait_time": 3600,
                    "heartbeat_interval": 300,
                    "quality_score": 10
                },
                {
                    "name": "mistral:7b",
                    "type": "generalist", 
                    "description": "Dobry w analizie i myÅ›leniu",
                    "max_wait_time": 300,
                    "heartbeat_interval": 120,
                    "quality_score": 9
                },
                {
                    "name": "llama3.1:8b",
                    "type": "fallback", 
                    "description": "Niezawodny fallback",
                    "max_wait_time": 180,
                    "heartbeat_interval": 60,
                    "quality_score": 8
                }
            ],
            "general": [
                {
                    "name": "llama3.1:8b",
                    "type": "primary", 
                    "description": "GÅ‚Ã³wny model ogÃ³lny",
                    "max_wait_time": 300,
                    "heartbeat_interval": 120,
                    "quality_score": 8
                },
                {
                    "name": "llama3.2:3b",
                    "type": "fast", 
                    "description": "Szybkie odpowiedzi",
                    "max_wait_time": 120,
                    "heartbeat_interval": 60,
                    "quality_score": 7
                },
                {
                    "name": "mistral:7b",
                    "type": "alternative", 
                    "description": "Alternatywny wybÃ³r",
                    "max_wait_time": 300,
                    "heartbeat_interval": 120,
                    "quality_score": 8
                }
            ]
        }
    
    def analyze_task(self, task_description):
        """Analiza zadania dla wyboru odpowiedniej hierarchii modeli"""
        task_lower = task_description.lower()
        
        coding_keywords = [
            "kod", "code", "python", "javascript", "function", "program", 
            "bug", "debug", "algorithm", "implementuj", "napisz program", "script"
        ]
        
        reasoning_keywords = [
            "analiza", "analysis", "strategia", "strategy", "zaprojektuj", "design",
            "architektura", "optimization", "skalowanie", "scaling", "plan", "solve"
        ]
        
        if any(word in task_lower for word in coding_keywords):
            return "coding"
        elif any(word in task_lower for word in reasoning_keywords):
            return "reasoning" 
        else:
            return "general"
    
    def try_model_with_patience(self, model_config, task_description):
        """PrÃ³buje model z cierpliwoÅ›ciÄ… ale kontrolÄ… Å¼ycia"""
        
        model_name = model_config["name"]
        max_wait = model_config["max_wait_time"]
        heartbeat = model_config["heartbeat_interval"]
        
        print(f"\nğŸ¯ PrÃ³bujÄ™: {model_name}")
        print(f"   Typ: {model_config['type']}")
        print(f"   Opis: {model_config['description']}")
        print(f"   Max czas: {max_wait//60}min, kontrola Å¼ycia co: {heartbeat//60}min")
        
        def make_request(timeout=30):
            return requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": model_name,
                    "prompt": f"Agent Zero AI: {task_description}\n\nPodaj konkretnÄ…, praktycznÄ… odpowiedÅº:",
                    "stream": False,
                    "options": {"temperature": 0.2, "max_tokens": 300}
                },
                timeout=timeout
            )
        
        # Uruchom monitoring w osobnym wÄ…tku
        result_queue = Queue()
        monitor_thread = threading.Thread(
            target=heartbeat_monitor,
            args=(make_request, result_queue, heartbeat, max_wait)
        )
        
        start_time = time.time()
        monitor_thread.start()
        
        # Czekaj na rezultat
        try:
            status, result = result_queue.get(timeout=max_wait + 60)  # Extra buffer
            monitor_thread.join(timeout=10)  # Daj wÄ…tkowi czas na zakoÅ„czenie
            
            response_time = time.time() - start_time
            
            if status == "success":
                response_data = result.json()
                return {
                    "success": True,
                    "response": response_data.get("response", "").strip(),
                    "model_used": model_name,
                    "model_type": model_config["type"],
                    "response_time": round(response_time, 2),
                    "quality_score": model_config["quality_score"],
                    "waited_patiently": response_time > 300  # Czy czekaliÅ›my cierpliwie
                }
            else:
                return {
                    "success": False,
                    "error": result,
                    "model_attempted": model_name,
                    "response_time": round(response_time, 2),
                    "reason": status
                }
                
        except Empty:
            return {
                "success": False,
                "error": "Monitor thread nie odpowiedziaÅ‚",
                "model_attempted": model_name,
                "response_time": max_wait
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "model_attempted": model_name,
                "response_time": time.time() - start_time
            }
    
    def generate_response(self, task_description):
        """GÅ‚Ã³wna metoda z cierpliwym podejÅ›ciem"""
        print(f"\nğŸ¯ ZADANIE: {task_description}")
        
        # Wybierz hierarchiÄ™ modeli
        task_type = self.analyze_task(task_description)
        models = self.model_hierarchy[task_type]
        
        print(f"ğŸ“Š Typ zadania: {task_type}")
        print(f"ğŸ”„ Hierarchia modeli: {len(models)} kandydatÃ³w")
        
        # WyprÃ³buj modele w kolejnoÅ›ci
        for i, model_config in enumerate(models, 1):
            print(f"\n{'='*20} PRÃ“BA {i}/{len(models)} {'='*20}")
            
            result = self.try_model_with_patience(model_config, task_description)
            
            if result["success"]:
                print(f"\nâœ… SUKCES!")
                if result.get("waited_patiently"):
                    print(f"ğŸ•°ï¸ Cierpliwie poczekaliÅ›my na specjalistÄ™!")
                return result
            else:
                print(f"\nâŒ NIEPOWODZENIE:")
                print(f"   PowÃ³d: {result.get('reason', 'nieznany')}")
                print(f"   BÅ‚Ä…d: {result.get('error', 'brak szczegÃ³Å‚Ã³w')}")
                print(f"   Czas: {result.get('response_time', 0):.1f}s")
                
                if i < len(models):
                    print(f"ğŸ”„ PrzechodzÄ™ do nastÄ™pnego modelu...")
                else:
                    print(f"ğŸ˜ Wyczerpano wszystkie opcje")
        
        return {
            "success": False,
            "error": "Å»aden model z hierarchii nie byÅ‚ dostÄ™pny",
            "attempts": len(models)
        }

def main():
    print("ğŸš€ Agent Zero Phase 4 - CIERPLIWY System AI z KontrolÄ… Å»ycia")
    print("=" * 70)
    print(f"Czas: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ’¡ Specjalistom dajemy czas (do 1h), ale kontrolujemy czy Å¼yjÄ… (5min)!")
    
    ai_system = PatientAISystem()
    
    # Zadania testowe - od prostych do zÅ‚oÅ¼onych
    test_tasks = [
        "Napisz funkcjÄ™ sortujÄ…cÄ… w Python",
        "Jak zoptymalizowaÄ‡ PostgreSQL dla wysokiego ruchu?", 
        "Zaprojektuj architekturÄ™ mikrousÅ‚ug dla e-commerce",
        "Co to jest REST API?",
        "Strategia skalowania systemu AI dla miliona uÅ¼ytkownikÃ³w dziennie"
    ]
    
    print(f"\nğŸ§ª Testowanie z cierpliwym podejÅ›ciem:")
    
    successful_tests = 0
    specialist_successes = 0
    total_time = 0
    
    for i, task in enumerate(test_tasks, 1):
        print(f"\n" + "ğŸ¯" + "="*60)
        print(f"TEST {i}/{len(test_tasks)}")
        
        start = time.time()
        result = ai_system.generate_response(task)
        test_time = time.time() - start
        
        if result["success"]:
            successful_tests += 1
            total_time += result["response_time"]
            
            if result["model_type"] in ["specialist", "expert"]:
                specialist_successes += 1
                print(f"ğŸ† SPECJALISTA DOSTARCZYÅ!")
            
            print(f"\nğŸ‰ SUKCES w {test_time:.1f}s!")
            print(f"   Model: {result['model_used']} ({result['model_type']})")
            print(f"   Czas odpowiedzi: {result['response_time']}s")
            print(f"   JakoÅ›Ä‡: {result['quality_score']}/10")
            print(f"   OdpowiedÅº: {result['response'][:150]}...")
        else:
            print(f"\nğŸ’¥ NIEPOWODZENIE w {test_time:.1f}s")
            print(f"   BÅ‚Ä…d: {result.get('error', 'nieznany')}")
    
    print(f"\nğŸŠ CIERPLIWY TEST ZAKOÅƒCZONY!")
    print(f"âœ… Udane: {successful_tests}/{len(test_tasks)}")
    print(f"ğŸ† SpecjaliÅ›ci: {specialist_successes}/{successful_tests} sukcesÃ³w")
    if successful_tests > 0:
        print(f"â±ï¸ Åšredni czas: {total_time/successful_tests:.1f}s")
    print(f"ğŸ§  CierpliwoÅ›Ä‡ + kontrola Å¼ycia = najlepsza jakoÅ›Ä‡ odpowiedzi!")

if __name__ == "__main__":
    main()