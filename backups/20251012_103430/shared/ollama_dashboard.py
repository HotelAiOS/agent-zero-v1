import os
import sys
import signal
import time
from datetime import datetime
from typing import Dict, Any
from dataclasses import dataclass
from enum import Enum

# Try importing ollama
try:
    import ollama
    OLLAMA_AVAILABLE = True
    print("âœ… Ollama client zaimportowany")
except ImportError:
    OLLAMA_AVAILABLE = False
    print("âš ï¸ Ollama client niedostÄ™pny - bÄ™dzie symulacja")

class AgentState(Enum):
    IDLE = "ğŸ’¤ idle"
    ANALYZING = "ğŸ” analyzing"
    LOADING = "â³ loading"
    THINKING = "ğŸ¤” thinking"
    GENERATING = "ğŸ”¥ generating"
    COMPLETED = "âœ… completed"
    ERROR = "âŒ error"
    STOPPED = "ğŸ›‘ stopped"

@dataclass
class Agent:
    agent_id: str
    state: AgentState
    prompt: str = ""
    tokens: int = 0
    start_time: float = 0
    model: str = "llama3.2:3b"
    response: str = ""
    error_message: str = ""

class OllamaDashboard:
    def __init__(self):
        self.running = True
        self.agents: Dict[str, Agent] = {}
        self.available_models = []
        signal.signal(signal.SIGINT, self.signal_handler)
        
        # Check Ollama on startup
        self.check_ollama_status()
        
    def signal_handler(self, signum, frame):
        print("\nğŸ›‘ Emergency stop wszystkich agentÃ³w...")
        for agent in self.agents.values():
            if agent.state == AgentState.GENERATING:
                agent.state = AgentState.STOPPED
        self.running = False
        sys.exit(0)
    
    def check_ollama_status(self):
        """SprawdÅº status Ollama przy starcie"""
        if OLLAMA_AVAILABLE:
            try:
                models = ollama.list()
                if models and 'models' in models:
                    self.available_models = [m['name'] for m in models['models']]
                    print(f"âœ… Ollama OK - {len(self.available_models)} modeli dostÄ™pnych")
                else:
                    print("âš ï¸ Ollama poÅ‚Ä…czony ale brak modeli")
            except Exception as e:
                print(f"âŒ Ollama error: {e}")
        else:
            print("âŒ Ollama client niedostÄ™pny")
    
    def clear_screen(self):
        os.system('clear' if os.name == 'posix' else 'cls')
    
    def display_header(self):
        current_time = datetime.now().strftime('%H:%M:%S')
        ollama_status = "ğŸŸ¢ Online" if OLLAMA_AVAILABLE else "ğŸ”´ Offline"
        
        print("ğŸ›ï¸" + "="*60 + "ğŸ›ï¸")
        print("ğŸ§   OLLAMA LIVE DASHBOARD - AGENT ZERO  ğŸ§ ")
        print(f"â°  {current_time} | AgentÃ³w: {len(self.agents)} | Ollama: {ollama_status}")
        print(f"ğŸ¤–  Modeli dostÄ™pnych: {len(self.available_models)}")
        print("ğŸ›ï¸" + "="*60 + "ğŸ›ï¸")
    
    def display_agents(self):
        print(f"\nğŸ¤– AKTYWNI AGENCI ({len(self.agents)}):")
        print("-" * 60)
        
        if not self.agents:
            print("ğŸ’¤ Brak aktywnych agentÃ³w")
        else:
            for agent_id, agent in self.agents.items():
                runtime = int(time.time() - agent.start_time) if agent.start_time else 0
                print(f"{agent.state.value} {agent_id}")
                print(f"   â””â”€ Tokeny: {agent.tokens} | Czas: {runtime}s | Model: {agent.model}")
                if agent.prompt:
                    prompt_preview = agent.prompt[:50] + "..." if len(agent.prompt) > 50 else agent.prompt
                    print(f"   â””â”€ Prompt: {prompt_preview}")
                if agent.error_message:
                    print(f"   â””â”€ âŒ BÅ‚Ä…d: {agent.error_message}")
    
    def display_menu(self):
        print("\nğŸ® MENU:")
        print("1ï¸âƒ£  ğŸš€ Dodaj agenta")
        print("2ï¸âƒ£  ğŸ”¥ Generuj z Ollama" + (" (REAL)" if OLLAMA_AVAILABLE else " (SYM)"))
        print("3ï¸âƒ£  ğŸ“Š SzczegÃ³Å‚y agentÃ³w")
        print("4ï¸âƒ£  ğŸ›‘ Zatrzymaj agenta")
        print("5ï¸âƒ£  ğŸ—‘ï¸  UsuÅ„ wszystkich")
        print("6ï¸âƒ£  ğŸ§ª Test poÅ‚Ä…czenia Ollama")
        print("7ï¸âƒ£  ğŸ“‹ Lista modeli")
        print("8ï¸âƒ£  ğŸ”„ SprawdÅº status Ollama")
        print("0ï¸âƒ£  ğŸ‘‹ WyjÅ›cie")
        print("\nğŸ‘† Wybierz opcjÄ™: ", end="")
    
    def add_agent(self):
        agent_id = f"agent-{len(self.agents)+1:03d}"
        
        print(f"\nğŸš€ Tworzenie agenta: {agent_id}")
        prompt = input("ğŸ“ Wpisz prompt: ").strip()
        
        if not prompt:
            prompt = "Napisz prostÄ… funkcjÄ™ hello world w Pythonie z komentarzami"
            print(f"ğŸ“ UÅ¼yto domyÅ›lnego promptu")
        
        # WybÃ³r modelu
        if self.available_models:
            print("\nğŸ§  DostÄ™pne modele:")
            for i, model in enumerate(self.available_models, 1):
                print(f"{i}. {model}")
            
            try:
                choice = input("Wybierz model (Enter = default): ").strip()
                if choice.isdigit() and 1 <= int(choice) <= len(self.available_models):
                    selected_model = self.available_models[int(choice)-1]
                else:
                    selected_model = self.available_models[0] if self.available_models else "llama3.2:3b"
            except:
                selected_model = "llama3.2:3b"
        else:
            selected_model = "llama3.2:3b"
        
        agent = Agent(
            agent_id=agent_id,
            state=AgentState.IDLE,
            prompt=prompt,
            start_time=time.time(),
            model=selected_model
        )
        
        self.agents[agent_id] = agent
        print(f"âœ… Agent {agent_id} utworzony z modelem {selected_model}!")
        input("â NaciÅ›nij Enter...")
    
    def generate_with_ollama(self):
        if not self.agents:
            print("âŒ Brak agentÃ³w!")
            input("â NaciÅ›nij Enter...")
            return
        
        print("\nğŸ”¥ GENERACJA Z OLLAMA")
        print("DostÄ™pni agenci:")
        for i, agent_id in enumerate(self.agents.keys(), 1):
            agent = self.agents[agent_id]
            print(f"{i}. {agent_id} ({agent.state.value}) - {agent.model}")
        
        try:
            choice = int(input("Wybierz agenta: ")) - 1
            agent_ids = list(self.agents.keys())
            
            if 0 <= choice < len(agent_ids):
                selected_agent = agent_ids[choice]
                self.run_ollama_generation(selected_agent)
            else:
                print("âŒ NieprawidÅ‚owy wybÃ³r!")
        except ValueError:
            print("âŒ Wpisz numer!")
        
        input("â NaciÅ›nij Enter...")
    
    def run_ollama_generation(self, agent_id: str):
        agent = self.agents[agent_id]
        
        print(f"\nğŸš€ Rozpoczynanie generacji dla {agent_id}")
        print(f"ğŸ§  Model: {agent.model}")
        print(f"ğŸ“ Prompt: {agent.prompt}")
        print("-" * 40)
        
        try:
            # Stage 1: Analyzing
            agent.state = AgentState.ANALYZING
            print("ğŸ” AnalizujÄ™ prompt...")
            time.sleep(0.5)
            
            # Stage 2: Loading
            agent.state = AgentState.LOADING
            print("â³ ÅadujÄ™ model...")
            time.sleep(1)
            
            # Stage 3: Generating
            agent.state = AgentState.GENERATING
            print("ğŸ”¥ Rozpoczynam generacjÄ™...\n")
            
            if OLLAMA_AVAILABLE:
                # Prawdziwa generacja z Ollama
                response_text = ""
                
                try:
                    response = ollama.generate(
                        model=agent.model,
                        prompt=agent.prompt,
                        stream=True
                    )
                    
                    print("ğŸ“ OdpowiedÅº:")
                    print("-" * 20)
                    
                    for chunk in response:
                        if 'response' in chunk:
                            token = chunk['response']
                            print(token, end='', flush=True)
                            response_text += token
                            agent.tokens += 1
                            
                            # Pokazuj progress co 10 tokenÃ³w
                            if agent.tokens % 10 == 0:
                                print(f" [{agent.tokens}]", end='', flush=True)
                    
                    agent.response = response_text
                    agent.state = AgentState.COMPLETED
                    print(f"\n\nâœ… Generacja zakoÅ„czona!")
                    print(f"ğŸ“Š Wygenerowano {agent.tokens} tokenÃ³w")
                    
                except Exception as e:
                    agent.state = AgentState.ERROR
                    agent.error_message = str(e)
                    print(f"\nâŒ BÅ‚Ä…d Ollama: {e}")
            else:
                # Symulacja
                print("âš ï¸ Symulacja (Ollama niedostÄ™pny):")
                sample_response = f"""
def hello_world():
    \"\"\"
    Prosta funkcja wyÅ›wietlajÄ…ca powitanie.
    \"\"\"
    print("Hello, World!")
    return "Hello, World!"

# WywoÅ‚anie funkcji
if __name__ == "__main__":
    hello_world()
"""
                
                for char in sample_response:
                    print(char, end='', flush=True)
                    agent.tokens += 1
                    if char in [' ', '\n']:
                        time.sleep(0.05)
                
                agent.response = sample_response
                agent.state = AgentState.COMPLETED
                print(f"\nâœ… Symulacja zakoÅ„czona! Tokeny: {agent.tokens}")
                
        except KeyboardInterrupt:
            agent.state = AgentState.STOPPED
            print(f"\nğŸ›‘ Generacja przerwana przez uÅ¼ytkownika!")
        except Exception as e:
            agent.state = AgentState.ERROR
            agent.error_message = str(e)
            print(f"\nâŒ BÅ‚Ä…d: {e}")
    
    def show_details(self):
        if not self.agents:
            print("ğŸ’¤ Brak agentÃ³w")
            input("â NaciÅ›nij Enter...")
            return
        
        print("\nğŸ“Š SZCZEGÃ“ÅY AGENTÃ“W:")
        print("=" * 60)
        
        for agent_id, agent in self.agents.items():
            runtime = int(time.time() - agent.start_time) if agent.start_time else 0
            
            print(f"\nğŸ¤– Agent: {agent_id}")
            print(f"   Status: {agent.state.value}")
            print(f"   Model: {agent.model}")
            print(f"   Tokeny: {agent.tokens}")
            print(f"   Czas: {runtime}s")
            print(f"   Prompt: {agent.prompt}")
            
            if agent.response:
                response_preview = agent.response[:100] + "..." if len(agent.response) > 100 else agent.response
                print(f"   OdpowiedÅº: {response_preview}")
            
            if agent.error_message:
                print(f"   BÅ‚Ä…d: {agent.error_message}")
        
        input("\nâ NaciÅ›nij Enter...")
    
    def test_ollama_connection(self):
        print("\nğŸ§ª TEST POÅÄ„CZENIA OLLAMA")
        print("-" * 30)
        
        if not OLLAMA_AVAILABLE:
            print("âŒ Ollama client niedostÄ™pny")
            input("â NaciÅ›nij Enter...")
            return
        
        try:
            print("ğŸ“¡ Sprawdzanie poÅ‚Ä…czenia...")
            models = ollama.list()
            
            if models and 'models' in models:
                print("âœ… PoÅ‚Ä…czenie OK!")
                print(f"ğŸ“‹ DostÄ™pne modele ({len(models['models'])}):")
                for model in models['models']:
                    print(f"   ğŸ§  {model['name']}")
                    
                # Quick test generation
                print("\nğŸ§ª Test szybkiej generacji...")
                test_response = ollama.generate(
                    model="llama3.2:3b",  # Podstawowy model
                    prompt="Odpowiedz jednym sÅ‚owem: 'Test'",
                    stream=False
                )
                
                if test_response and 'response' in test_response:
                    print(f"âœ… Test response: {test_response['response'][:50]}")
                else:
                    print("âš ï¸ Brak odpowiedzi w teÅ›cie")
                    
            else:
                print("âš ï¸ PoÅ‚Ä…czenie OK ale brak modeli")
                
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d poÅ‚Ä…czenia: {e}")
        
        input("\nâ NaciÅ›nij Enter...")
    
    def list_models(self):
        print("\nğŸ“‹ LISTA MODELI OLLAMA")
        print("-" * 30)
        
        if not self.available_models:
            if OLLAMA_AVAILABLE:
                print("âš ï¸ Brak dostÄ™pnych modeli")
                print("ğŸ’¡ SprÃ³buj: ollama pull llama3.2:3b")
            else:
                print("âŒ Ollama client niedostÄ™pny")
        else:
            print(f"âœ… DostÄ™pne modele ({len(self.available_models)}):")
            for i, model in enumerate(self.available_models, 1):
                print(f"{i}. ğŸ§  {model}")
        
        input("\nâ NaciÅ›nij Enter...")
    
    def refresh_ollama_status(self):
        print("\nğŸ”„ ODÅšWIEÅ»ANIE STATUSU OLLAMA")
        print("-" * 30)
        self.check_ollama_status()
        input("â NaciÅ›nij Enter...")
    
    def stop_agent(self):
        if not self.agents:
            print("âŒ Brak agentÃ³w!")
            input("â NaciÅ›nij Enter...")
            return
        
        print("\nğŸ›‘ ZATRZYMYWANIE AGENTA")
        for i, agent_id in enumerate(self.agents.keys(), 1):
            agent = self.agents[agent_id]
            print(f"{i}. {agent_id} ({agent.state.value})")
        
        try:
            choice = int(input("Wybierz agenta: ")) - 1
            agent_ids = list(self.agents.keys())
            
            if 0 <= choice < len(agent_ids):
                selected_agent = agent_ids[choice]
                self.agents[selected_agent].state = AgentState.STOPPED
                print(f"ğŸ›‘ Agent {selected_agent} zatrzymany!")
            else:
                print("âŒ NieprawidÅ‚owy wybÃ³r!")
        except ValueError:
            print("âŒ Wpisz numer!")
        
        input("â NaciÅ›nij Enter...")
    
    def clear_agents(self):
        count = len(self.agents)
        self.agents.clear()
        print(f"ğŸ—‘ï¸ UsuniÄ™to {count} agentÃ³w!")
        input("â NaciÅ›nij Enter...")
    
    def run(self):
        print("ğŸš€ Uruchamianie Ollama Dashboard...")
        print("ğŸ›‘ UÅ¼yj Ctrl+C dla emergency stop\n")
        
        while self.running:
            try:
                self.clear_screen()
                self.display_header()
                self.display_agents()
                self.display_menu()
                
                choice = input().strip()
                
                if choice == '1':
                    self.add_agent()
                elif choice == '2':
                    self.generate_with_ollama()
                elif choice == '3':
                    self.show_details()
                elif choice == '4':
                    self.stop_agent()
                elif choice == '5':
                    self.clear_agents()
                elif choice == '6':
                    self.test_ollama_connection()
                elif choice == '7':
                    self.list_models()
                elif choice == '8':
                    self.refresh_ollama_status()
                elif choice == '0':
                    print("ğŸ‘‹ Zamykanie dashboard...")
                    break
                else:
                    print("âŒ NieprawidÅ‚owy wybÃ³r!")
                    time.sleep(1)
                    
            except KeyboardInterrupt:
                print("\nğŸ›‘ Emergency stop aktywowany!")
                break
            except Exception as e:
                print(f"âŒ BÅ‚Ä…d: {e}")
                input("â NaciÅ›nij Enter...")
        
        print("âœ… Dashboard zakoÅ„czony!")

def main():
    dashboard = OllamaDashboard()
    dashboard.run()

if __name__ == "__main__":
    main()
